from driver.core import ConfigContainer
from pyspark.sql import DataFrame
from pytest import fixture
from pyspark.sql.types import StringType, StructField, StructType, IntegerType, LongType, DoubleType, TimestampType

# todo: adapt this to your Environment
DEFAULT_BUCKET = "s3://test-bucket"


@fixture
def app_args() -> ConfigContainer:
    args = ConfigContainer()
    setattr(args, "default_data_lake_bucket", DEFAULT_BUCKET)
    return args

{% if models is defined %}
{% set input_models = input_ids|map('split_and_pick',-1) %}

{% for model in models %}
@fixture(scope="module")
def {{ model.id }}_schema() -> StructType:
    return StructType(
        [
        {% for col in model.columns %}
        StructField("{{ col.id }}", {{ col.type | convert_type_name }}(), {{ col | is_nullable }}),
        {% endfor %}
        ]
    )

{% if model.id in input_models %}
@fixture(scope="module")
def {{ model.id }}_df(spark_session, {{ model.id }}_schema) -> DataFrame:
    return spark_session.createDataFrame(
        [
        {% for n in range(5) %}
            ({{ model.columns|map('faker') |join(', ') }}),
        {% endfor %}
        ],
        {{ model.id }}_schema,
    )
{% endif %}

{% endfor %}
{% endif %}
